{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPjQw+CjuLYLBfiwvk26f2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Bank Customer Churn Predictor**\n",
        "This notebook builds bank customer churn predictior using the `Bank Customer Churn Prediction` Kaggle dataset by `shantanudhakadd`\n",
        "\n",
        "---\n",
        "Following libraries must be installed:\n",
        "\n",
        "- Numpy\n",
        "- Pandas\n",
        "- Matplotlib\n",
        "- Seaborn\n",
        "- Sklearn\n",
        "- Pickle\n",
        "\n"
      ],
      "metadata": {
        "id": "82z-Rq8KkYQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import libraries**\n",
        "\n",
        "Following cell imports all th libraries, classes and functions used in this notebook."
      ],
      "metadata": {
        "id": "BzTE3jx8rhh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "import pickle"
      ],
      "metadata": {
        "id": "2cD_k5yUNjS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load dataset**\n",
        "\n",
        "Following cells downloads the dataset and loads it into the code."
      ],
      "metadata": {
        "id": "nF3e3pf2sq9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download dataset\n",
        "\n",
        "Following cell downloads the `Bank Customer Churn Prediction` Kaggle dataset by `shantanudhakadd` and unzips the csv file from the .zip file."
      ],
      "metadata": {
        "id": "2O0ETxW1tH3R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kZWzXxLKIei"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d shantanudhakadd/bank-customer-churn-prediction\n",
        "!unzip bank-customer-churn-prediction.zip\n",
        "!rm bank-customer-churn-prediction.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load dataset\n",
        "\n",
        "Following cell loads the dataset from `Churn_Modelling.csv` to variable `churn_data`."
      ],
      "metadata": {
        "id": "vMRdV32ztlIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "churn_data = pd.read_csv('Churn_Modelling.csv')\n",
        "churn_data.head()"
      ],
      "metadata": {
        "id": "vCr18RENOPAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EDA**\n",
        "\n",
        "Following cells perforn exploratory data analysis."
      ],
      "metadata": {
        "id": "Yrw6E5p2tyuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic info of data\n",
        "\n",
        "Display the number of rows, number of columns, datatype of each column and non-null values in each column."
      ],
      "metadata": {
        "id": "FIoVOceruIqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "churn_data.info()"
      ],
      "metadata": {
        "id": "0W0h28N8OjN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unique value count\n",
        "\n",
        "Display the number of unique values in each column."
      ],
      "metadata": {
        "id": "zkqPvFzcvHm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in churn_data.columns:\n",
        "    print(f'{column} : {churn_data[column].nunique()}')"
      ],
      "metadata": {
        "id": "uGv6JTdYO91E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical description of data\n",
        "\n",
        "Display basic statistics such as mean, standard deviation min, max etc for each column."
      ],
      "metadata": {
        "id": "D8XFlFH2vlnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "churn_data.describe()"
      ],
      "metadata": {
        "id": "_a2bJG4OPYS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Numerical\n",
        "\n",
        "Plot numerical columns `Age`, `Balance`, `EstimatedSalary`, and `CreditScore` as histograms."
      ],
      "metadata": {
        "id": "WUZfSBrtwFVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15, 6))\n",
        "\n",
        "to_plot = ['Age', 'Balance', 'EstimatedSalary', 'CreditScore']\n",
        "\n",
        "## Plot graphs\n",
        "for i, column in enumerate(to_plot, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.histplot(x = column, data = churn_data, hue = 'Exited', stat='percent', kde = True, bins = 20, multiple='stack')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3Z-zvvQCPiyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot categorical\n",
        "\n",
        "Plot categorical columns `Tenure`, `Gender`, `HasCrCard`, `IsActiveMember`, `Geography`, and `NumOfProducts` as histograms."
      ],
      "metadata": {
        "id": "yuYmvD3dwfmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15, 8))\n",
        "\n",
        "to_plot = ['Tenure', 'Gender', 'HasCrCard', 'IsActiveMember', 'Geography', 'NumOfProducts']\n",
        "\n",
        "## Plot graphs\n",
        "for i, column in enumerate(to_plot, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.histplot(x = column, data = churn_data, hue = 'Exited', stat = 'percent', multiple = 'dodge', bins = churn_data[column].nunique(), palette='tab10')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QoE9vWSUBI-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot target\n",
        "\n",
        "Plot target column `Exited` as pie chart."
      ],
      "metadata": {
        "id": "noCCHjAvw6n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(churn_data.Exited.value_counts(), labels = ['Retained', 'Exited'], autopct='%1.1f%%', colors=sns.color_palette('tab10'), explode=[0, 0.1], shadow=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x1vFj9f6fspA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check null\n",
        "\n",
        "Display number of null values in each column"
      ],
      "metadata": {
        "id": "bPEET3u2xP0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "churn_data.isnull().sum()"
      ],
      "metadata": {
        "id": "PJVfMTxEDYQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check duplicates\n",
        "\n",
        "Display number of duplicate rows."
      ],
      "metadata": {
        "id": "UEXR-MKpxXuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "churn_data.duplicated(subset = 'CustomerId').sum()"
      ],
      "metadata": {
        "id": "WMbbHyMEKGzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing**\n",
        "\n",
        "Following cells selects useful features, split data into train and test sets, encode categorical columns"
      ],
      "metadata": {
        "id": "mKyLQS5CxlVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select features\n",
        "\n",
        "Drop redundant and not useful columns. Seprate target from features."
      ],
      "metadata": {
        "id": "qXCs22C9ziAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop = ['RowNumber', 'CustomerId', 'Surname', 'Exited']\n",
        "X_full = churn_data.drop(to_drop, axis = 1)\n",
        "y_full= churn_data.Exited\n",
        "\n",
        "X_full.head()"
      ],
      "metadata": {
        "id": "dmIoUbsZKeUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test split\n",
        "\n",
        "Split data into training and testing sets in a ratio of 20%."
      ],
      "metadata": {
        "id": "DX3_AU4qzaHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size = 0.2, random_state = 42)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "gvyPiPMwMyPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode categorical columns\n",
        "\n",
        "Use one hot encoding to encode categorical columns `Georaphy` and `Gender`."
      ],
      "metadata": {
        "id": "NILa7oDb0Hvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode 'Geography'\n",
        "X_train = pd.get_dummies(X_train, columns = ['Geography'], dtype = int)\n",
        "X_test = pd.get_dummies(X_test, columns = ['Geography'], dtype=int)\n",
        "\n",
        "# One hot encode 'Gender'\n",
        "X_train.Gender = X_train.Gender.map({'Male': 0, 'Female': 1})\n",
        "X_test.Gender = X_test.Gender.map({'Male': 0, 'Female': 1})\n",
        "\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "3XJp5iWdRGu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scale data\n",
        "\n",
        "Use standard scaling to scale `EstimatedSalary` and `Balance` column."
      ],
      "metadata": {
        "id": "NlvE1GiW0d1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train['EstimatedSalary'], X_train['Balance'] = scaler.fit_transform(X_train[['EstimatedSalary', 'Balance']]).transpose()\n",
        "X_test['EstimatedSalary'], X_test['Balance'] = scaler.transform(X_test[['EstimatedSalary', 'Balance']]).transpose()\n",
        "\n",
        "X_train.describe().apply(lambda s: s.apply('{0:.5f}'.format))"
      ],
      "metadata": {
        "id": "MOlyhcg8WPkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check correlation\n",
        "\n",
        "Display correlation of each feature with the target."
      ],
      "metadata": {
        "id": "HD1RkHSx0ylO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.corrwith(y_train).abs().sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "WKdDNYseSu8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train Model**\n",
        "\n",
        "Following cells train and evaluate different models to find the best prediction model."
      ],
      "metadata": {
        "id": "P4lk04xO1f_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate\n",
        "\n",
        "Following cell describes function `train_evaluate` which train a model on training data and evaluates different metrics such as accuracy, confusion matrix and f1 score."
      ],
      "metadata": {
        "id": "3hdnNCdm2R7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate(model):\n",
        "    \"\"\"\n",
        "    Trains a model and evaluates its performance on the test set.\n",
        "    \"\"\"\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate model\n",
        "    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "    print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "cCFLqfM3Xu70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic regression"
      ],
      "metadata": {
        "id": "t9oO6mVO2y_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LogisticRegression(max_iter=500, random_state = 3)\n",
        "train_evaluate(LR)"
      ],
      "metadata": {
        "id": "B6AqRHpgaxGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest classifier"
      ],
      "metadata": {
        "id": "9RNbBJdm24LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RFC = RandomForestClassifier(n_estimators=300, random_state=3)\n",
        "train_evaluate(RFC)"
      ],
      "metadata": {
        "id": "vBbyD92ma3KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient boosting classifier"
      ],
      "metadata": {
        "id": "y7vWx8I92_l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GBC = GradientBoostingClassifier(n_estimators = 1000, random_state=3)\n",
        "train_evaluate(GBC)"
      ],
      "metadata": {
        "id": "TYTdm3wme61E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Final model**\n",
        "\n",
        "Following cells train the best model i.e. Gradient boosting classifier on the whole data i.e. training and testing data combined and finally saves the model."
      ],
      "metadata": {
        "id": "cartwiH53FJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model on full data\n",
        "\n",
        "Join train and test data, train model and display final f1 score"
      ],
      "metadata": {
        "id": "2eMFF0ZB3cYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_full = pd.concat([X_train, X_test])\n",
        "y_full = pd.concat([y_train, y_test])\n",
        "\n",
        "GBC.fit(X_full, y_full)\n",
        "print(\"F1 score: \")\n",
        "f1_score(y_full, GBC.predict(X_full))"
      ],
      "metadata": {
        "id": "ZsFf0r9eggZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model\n",
        "\n",
        "Save the model to `churn_model.pkl`"
      ],
      "metadata": {
        "id": "iJs0Xb5e3uFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(GBC, open('churn_model.pkl', 'wb'))\n",
        "print('Model Saved')"
      ],
      "metadata": {
        "id": "wtqWD6Quumn_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}